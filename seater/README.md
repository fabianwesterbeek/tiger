# 📘 Project Title


## 🧑‍💻 Team Members
- Name 1 – email@example.com  
- Name 2 – email@example.com  
- Name 3 – email@example.com  

## 👥 Supervising TAs
- David Vos (Main Supervisor)
- Owen de Jong (Co-supervisor)


---

## 🧾 Project Abstract
_Provide a concise summary of your project, including the type of recommender system you're building, the key techniques used, and a brief two sentence summary of results._

---

## 📊 Summary of Results


### Reproducability 

_Summarize your key reproducability findings in bullet points._

### Extensions

_Summarize your key findings about the extensions you implemented in bullet points._

---

## 🛠️ Task Definition
_Define the recommendation task you are solving (e.g., sequential, generative, content-based, collaborative, ranking, etc.). Clearly describe inputs and outputs._

---

## 📂 Datasets

_Provide the following for all datasets, including the attributes you are considering to measure things like item fairness (for example)_:

- [ ] [Dataset Name](Link-to-dataset-DOI-or-URL)
  - [ ] Pre-processing: e.g., Removed items with fewer than 5 interactions, and users with fewer than 5 interactions
  - [ ] Subsets considered: e.g., Cold Start (5-10 items)
  - [ ] Dataset size: # users, # items, sparsity:
  - [ ] Attributes for user fairness (only include if used):
  - [ ] Attributes for item fairness (only include if used):
  - [ ] Attributes for group fairness (only include if used):
  - [ ] Other attributes (only include if used):

---

## 📏 Metrics

_Explain why these metrics are appropriate for your recommendation task and what they are measuring briefly._

- [ ] Metric #1
  - [ ] Description:


---

## 🔬 Baselines & Methods

_Describe each baseline, primary methods, and how they are implemented. Mention tools/frameworks used (e.g., Surprise, LightFM, RecBole, PyTorch)._
Describe each baseline
- [ ] [Baseline 1](Link-to-reference)
- [ ] [Baseline 2](Link-to-reference)


### 🧠 High-Level Description of Method

_Explain your approach in simple terms. Describe your model pipeline: data input → embedding/representation → prediction → ranking. Discuss design choices, such as use of embeddings, neural networks, or attention mechanisms._

---

## 🌱 Proposed Extensions

_List & briefly describe the extensions that you made to the original method, including extending evaluation e.g., other metrics or new datasets considered._



